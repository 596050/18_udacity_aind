{
  "title": "Heuristics Analysis",
  "cells": [
    {
      "type": "markdown",
      "data": "##Heuristics Analysis:\nThe initial leitmotiv of the custom heuristics was to have any initial assumption on what is considered a good rule of thumb for the evaluation of positions (due to the lack of previous knowledge in this game). Each custom evaluation function does only take into consideration its present state (Greedy), so as not to slow down the computation too much and be able to go deeper during the iterative deepening.\n\n###Custom_score:\nFirst idea was to implement just a function that took into consideration the available moves for each player, adding a component of double weight to the opposites number of free moves, i.e. *value = player_free_moves - weight * opponent_free_moves*.\n\nThe initial weight was though of 2, giving a double weight in the freedom of the opponent. Thus, provoking an aggressive behavior leading to positions where the opponent had less able movements compared to the player, an 'imprisonment technique'.\n\nResult based on a 25 matches round, gave a score on average 7% above the 'AB_Imnproved' agent (xx% versus xx%).\n\n###Custom_score_2:\nBuilding upon an additional layer of complexity, I decided to modulate this 'agressivity' depending on the free space on the board. \n\nThe free space on the board is used as a proxy of the advancement of the game, i.e. how much turns have already developed. The advancement is divided into 3 brackets:\n - Upper bracket: 40 or more free spaces; depth coefficient = 0.5 .\n - Middle bracket: 30 or more free spaces; depth coefficient = 1 .\n - Low bracket: depth coefficient = 1.5 .\n\nThe resulting evaluation function resulted in:\n*value = player_free_moves - weight * coef_depth * opponent_free_moves*\n\n###Custom_score_3:\nLast idea was to add additional information in order to make the algorithm behave more aggresively:\n- Limiting opponents free moves\n- Augmenting aggresivity as we move the horitzon line\n- Penalizing the spread of player, trying to favor player movements that followed the opponent.\n\nThis last point is the added part in the **custom_score** , the distance used is the [euclidean one](https://en.wikipedia.org/wiki/Euclidean_distance).\n\n![Euclidean Distance.jpeg](quiver-image-url/5769EEFDE533EABBD5125169A511EF50.jpg =528x142)\n\nThe distance was divided into the same 3 previous brackets:\n - Upper bracket: 40 or more free spaces; distance coefficient = 1 .\n - Middle bracket: 30 or more free spaces; distance coefficient = 2 .\n - Low bracket: distance coefficient = 3 .\n\nThe resulting evaluation function resulted in:\n*value = player_free_moves - (weight * coef_depth * opponent_free_moves + coef_dist * distance_players)*"
    },
    {
      "type": "markdown",
      "data": "## Conclusion:\n###Results:\nResults obtained from a 100 games simulation with the following parameters:\n| Parameter | Value |\n| --------- | ----- |\n| Weight    |   2   |\n| Brackets | 40 / 30 / rest |\n| Depth coefficient | 0.5 / 1.0 / 1.5 |\n| Distance coefficient | 1 / 2 / 3 |\n\nResults from the provided tournament function (win rate):\n - AB_Improved 64.1%   \n - AB_Custom 64.1%  \n - AB_Custom_2 62.6%  \n - AB_Custom_3 63.8%\n \n![Won.jpeg](quiver-image-url/93DBDF1C6C748C056B78D14FEB0AEB81.jpg =1134x461)\n![Defeated.jpeg](quiver-image-url/12CA8CB8B601286A9D27DF81361DE25B.jpg =1094x453)\n\nA further graphical analyse, taking all matches in consideration (in case of AB_Improved the opponent matches where not taken in account) for each agent, i,e 1400 matches per agent.\n\nHere in this case, we see a different picture. Where **AB_Custom_3** agent performs slightly worse than the agent to beat **AB_Improved**, thus discarting it from further comparison.\nIn the case of **AB_Custom_1** and **AB_Custom_2**, both have a better performance than the 'to beat' threshold (**AB_Improved**). Initially **AB_Custom_1** shows a smaller spread in data compared to **AB_Custom_2**, value that may be interpreted as being more consistent. Even though having considered big sample of played games for each agent (1400 matches) the **AB_Custom_2** peforms overall better. \n\nBeing the best agent overall the **AB_Custom_2**.\n\n####Results disclaimer:\nIn this case we favourise the median (shown in graphics) against the mean (used in the provision of tournament functions). With further knowledge to add weights to each type of opponent, advising which is the strategy that is more similar to humans is hard to foresee. Thus, taking the median as a value less prove to extremes influences, being in consequence the defacto measuring tecnhique.\n\n\n###Reasoning:\n\nApparently the simple heuristic (**AB_Custom_1**) works already better than the **AB_Improved**. This points us in the direction of considering the fact that being able to go deeper in the 'tree horizont' helps far more than complex *\"greedy\"* heuristics, basing our assumptions on the fact that a complexer heuristic will require more computational time. \n\nMovin to compare between **AB_Custom_1** and **AB_Custom_2**, both heuristics are pretty simple, one taking just weighted available moves difference as evaluation function and the second one adding a rough weight tunning based on increasing the weight depending on the number of free available moves on the board. This heuristic of the number of free moves in the board, has been choosen as a proxy of the progression of the game (with zero knowledge of the game real median lenght), favorising the closer to the mean game end a strategy even more aggresive than the previously applied, our algorithm craves wins the closer to them. \n\nComenting on **AB_Custom_3** low performance, as this algorithm is constructed on the top of the **AB_Custom_2**, it starts to add the burden of more calculation (reducing the depth achieved in the horitzon for each turn). Additionally, it seems that the distance, though adding to the aggressivity of the agent, *the closer I get to my adversary, the easier to trap it* (non proved  assumption), is not properly calibrated in conjunction with the other weights. \n\n####Reasoning disclaimer:\nAggresivity is just the result of valing more each available movement of the opponent, than our own (weight 2, i.e. double valuation of opponent available legla moves). This makes in consequence valuing better the possible future game caonfigurations where our agent has more available movements. Leading in the long run to ending positions where we have more mobility, key factor for winning (having still legal movement where the opponents has no more).\n\n###Futher Improvements:\nThe heuristics are simple and *further improvements ought to come from more advanced techniques*, for example: using the number of moves already played (opposed to the number of free spaces available). This could be calibrated in addition with a knowledge on the average game length, so as to distribute the brackets better, in order to fine tune the aggressivity. Additionally, having greater computational power would allow to implement a **'search grid'** algorithm in order to fine tune the parameters, to the most optimal ones. Furthermore, proving the assumption of the closer I get to my adversary the more likely to win, would be need to be prooft.\nAs a lsat improvment point, having a testing agent that performed more as a human, would help a lot, as it would inform us better on the **parameters values** and **added heuristics** that outperform human ability."
    },
    {
      "type": "text",
      "data": "<br>"
    },
    {
      "type": "latex",
      "language": "latex",
      "data": ""
    }
  ]
}